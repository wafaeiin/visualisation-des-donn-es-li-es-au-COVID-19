{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "485cd7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: unrecognized arguments: # Pour afficher les graphiques directement dans le notebook\n"
     ]
    }
   ],
   "source": [
    "# Importation des packages / bibliothèques nécessaires\n",
    "import os  # Fournit des fonctions pour interagir avec le système d'exploitation\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, explained_variance_score, mean_absolute_error, mean_squared_error\n",
    "from math import sqrt\n",
    "from datetime import datetime\n",
    "\n",
    "%matplotlib inline  # Pour afficher les graphiques directement dans le notebook\n",
    "\n",
    "# Pour installer scikit-learn, tapez \"pip install numpy scipy scikit-learn\" dans le terminal Anaconda\n",
    "\n",
    "# Pour changer les nombres scientifiques en flottants\n",
    "np.set_printoptions(formatter={'float_kind':'{:f}'.format})\n",
    "\n",
    "# Augmente la taille des graphiques seaborn\n",
    "sns.set(rc={'figure.figsize':(12,10)})\n",
    "\n",
    "# Pour vérifier les packages installés\n",
    "# import sys\n",
    "# !conda list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d9d371ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Shape of Cornirmed is:  (225, 50)\n",
      "The Shape of Cornirmed is:  (225, 50)\n",
      "The Shape of Cornirmed is:  (225, 50)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>1/22/20</th>\n",
       "      <th>1/23/20</th>\n",
       "      <th>1/24/20</th>\n",
       "      <th>1/25/20</th>\n",
       "      <th>1/26/20</th>\n",
       "      <th>1/27/20</th>\n",
       "      <th>...</th>\n",
       "      <th>2/27/20</th>\n",
       "      <th>2/28/20</th>\n",
       "      <th>2/29/20</th>\n",
       "      <th>3/1/20</th>\n",
       "      <th>3/2/20</th>\n",
       "      <th>3/3/20</th>\n",
       "      <th>3/4/20</th>\n",
       "      <th>3/5/20</th>\n",
       "      <th>3/6/20</th>\n",
       "      <th>3/7/20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anhui</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>31.8257</td>\n",
       "      <td>117.2264</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>39</td>\n",
       "      <td>60</td>\n",
       "      <td>70</td>\n",
       "      <td>...</td>\n",
       "      <td>989</td>\n",
       "      <td>990</td>\n",
       "      <td>990</td>\n",
       "      <td>990</td>\n",
       "      <td>990</td>\n",
       "      <td>990</td>\n",
       "      <td>990</td>\n",
       "      <td>990</td>\n",
       "      <td>990</td>\n",
       "      <td>990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beijing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>40.1824</td>\n",
       "      <td>116.4142</td>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "      <td>36</td>\n",
       "      <td>41</td>\n",
       "      <td>68</td>\n",
       "      <td>80</td>\n",
       "      <td>...</td>\n",
       "      <td>410</td>\n",
       "      <td>410</td>\n",
       "      <td>411</td>\n",
       "      <td>413</td>\n",
       "      <td>414</td>\n",
       "      <td>414</td>\n",
       "      <td>418</td>\n",
       "      <td>418</td>\n",
       "      <td>422</td>\n",
       "      <td>426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chongqing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>30.0572</td>\n",
       "      <td>107.8740</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "      <td>57</td>\n",
       "      <td>75</td>\n",
       "      <td>110</td>\n",
       "      <td>...</td>\n",
       "      <td>576</td>\n",
       "      <td>576</td>\n",
       "      <td>576</td>\n",
       "      <td>576</td>\n",
       "      <td>576</td>\n",
       "      <td>576</td>\n",
       "      <td>576</td>\n",
       "      <td>576</td>\n",
       "      <td>576</td>\n",
       "      <td>576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fujian</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>26.0789</td>\n",
       "      <td>117.9874</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>35</td>\n",
       "      <td>59</td>\n",
       "      <td>...</td>\n",
       "      <td>296</td>\n",
       "      <td>296</td>\n",
       "      <td>296</td>\n",
       "      <td>296</td>\n",
       "      <td>296</td>\n",
       "      <td>296</td>\n",
       "      <td>296</td>\n",
       "      <td>296</td>\n",
       "      <td>296</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gansu</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>36.0611</td>\n",
       "      <td>103.8343</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>102</td>\n",
       "      <td>119</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province/State  Country/Region      Lat      Long  1/22/20  1/23/20  \\\n",
       "0          Anhui  Mainland China  31.8257  117.2264        1        9   \n",
       "1        Beijing  Mainland China  40.1824  116.4142       14       22   \n",
       "2      Chongqing  Mainland China  30.0572  107.8740        6        9   \n",
       "3         Fujian  Mainland China  26.0789  117.9874        1        5   \n",
       "4          Gansu  Mainland China  36.0611  103.8343        0        2   \n",
       "\n",
       "   1/24/20  1/25/20  1/26/20  1/27/20  ...  2/27/20  2/28/20  2/29/20  3/1/20  \\\n",
       "0       15       39       60       70  ...      989      990      990     990   \n",
       "1       36       41       68       80  ...      410      410      411     413   \n",
       "2       27       57       75      110  ...      576      576      576     576   \n",
       "3       10       18       35       59  ...      296      296      296     296   \n",
       "4        2        4        7       14  ...       91       91       91      91   \n",
       "\n",
       "   3/2/20  3/3/20  3/4/20  3/5/20  3/6/20  3/7/20  \n",
       "0     990     990     990     990     990     990  \n",
       "1     414     414     418     418     422     426  \n",
       "2     576     576     576     576     576     576  \n",
       "3     296     296     296     296     296     296  \n",
       "4      91      91      91     102     119     120  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chargement des données brutes cumulatives\n",
    "\n",
    "raw_data_confirmed = pd.read_csv('time_series_19-covid-Confirmed.csv')\n",
    "raw_data_deaths = pd.read_csv('time_series_19-covid-Deaths.csv')\n",
    "raw_data_Recovered = pd.read_csv('time_series_19-covid-Recovered.csv')\n",
    "\n",
    "print(\"The Shape of Cornirmed is: \", raw_data_confirmed.shape)\n",
    "print(\"The Shape of Cornirmed is: \", raw_data_deaths.shape)\n",
    "print(\"The Shape of Cornirmed is: \", raw_data_Recovered.shape)\n",
    "\n",
    "raw_data_confirmed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "154accb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>1/22/20</th>\n",
       "      <th>1/23/20</th>\n",
       "      <th>1/24/20</th>\n",
       "      <th>1/25/20</th>\n",
       "      <th>1/26/20</th>\n",
       "      <th>1/27/20</th>\n",
       "      <th>...</th>\n",
       "      <th>2/27/20</th>\n",
       "      <th>2/28/20</th>\n",
       "      <th>2/29/20</th>\n",
       "      <th>3/1/20</th>\n",
       "      <th>3/2/20</th>\n",
       "      <th>3/3/20</th>\n",
       "      <th>3/4/20</th>\n",
       "      <th>3/5/20</th>\n",
       "      <th>3/6/20</th>\n",
       "      <th>3/7/20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>King County, WA</td>\n",
       "      <td>US</td>\n",
       "      <td>47.6062</td>\n",
       "      <td>-122.3321</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Cook County, IL</td>\n",
       "      <td>US</td>\n",
       "      <td>41.7377</td>\n",
       "      <td>-87.6976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>US</td>\n",
       "      <td>34.0522</td>\n",
       "      <td>-118.2437</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>San Benito, CA</td>\n",
       "      <td>US</td>\n",
       "      <td>36.5761</td>\n",
       "      <td>-120.9876</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Madison, WI</td>\n",
       "      <td>US</td>\n",
       "      <td>43.0731</td>\n",
       "      <td>-89.4012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>Pierce County, WA</td>\n",
       "      <td>US</td>\n",
       "      <td>47.0676</td>\n",
       "      <td>-122.1295</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>Plymouth County, MA</td>\n",
       "      <td>US</td>\n",
       "      <td>42.1615</td>\n",
       "      <td>-70.7928</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>Santa Cruz County, CA</td>\n",
       "      <td>US</td>\n",
       "      <td>36.9741</td>\n",
       "      <td>-122.0308</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>Tulsa County, OK</td>\n",
       "      <td>US</td>\n",
       "      <td>36.1593</td>\n",
       "      <td>-95.9410</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>Montgomery County, TX</td>\n",
       "      <td>US</td>\n",
       "      <td>30.3213</td>\n",
       "      <td>-95.4778</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Province/State Country/Region      Lat      Long  1/22/20  \\\n",
       "35         King County, WA             US  47.6062 -122.3321        0   \n",
       "36         Cook County, IL             US  41.7377  -87.6976        0   \n",
       "46         Los Angeles, CA             US  34.0522 -118.2437        0   \n",
       "64          San Benito, CA             US  36.5761 -120.9876        0   \n",
       "66             Madison, WI             US  43.0731  -89.4012        0   \n",
       "..                     ...            ...      ...       ...      ...   \n",
       "220      Pierce County, WA             US  47.0676 -122.1295        0   \n",
       "221    Plymouth County, MA             US  42.1615  -70.7928        0   \n",
       "222  Santa Cruz County, CA             US  36.9741 -122.0308        0   \n",
       "223       Tulsa County, OK             US  36.1593  -95.9410        0   \n",
       "224  Montgomery County, TX             US  30.3213  -95.4778        0   \n",
       "\n",
       "     1/23/20  1/24/20  1/25/20  1/26/20  1/27/20  ...  2/27/20  2/28/20  \\\n",
       "35         0        0        0        0        0  ...        1        1   \n",
       "36         0        0        0        0        0  ...        2        2   \n",
       "46         0        0        0        0        0  ...        0        0   \n",
       "64         0        0        0        0        0  ...        0        0   \n",
       "66         0        0        0        0        0  ...        0        0   \n",
       "..       ...      ...      ...      ...      ...  ...      ...      ...   \n",
       "220        0        0        0        0        0  ...        0        0   \n",
       "221        0        0        0        0        0  ...        0        0   \n",
       "222        0        0        0        0        0  ...        0        0   \n",
       "223        0        0        0        0        0  ...        0        0   \n",
       "224        0        0        0        0        0  ...        0        0   \n",
       "\n",
       "     2/29/20  3/1/20  3/2/20  3/3/20  3/4/20  3/5/20  3/6/20  3/7/20  \n",
       "35         1       1       1       1       1       1       1       1  \n",
       "36         2       2       2       2       2       2       2       2  \n",
       "46         0       0       0       0       0       0       0       0  \n",
       "64         0       0       0       0       0       0       0       0  \n",
       "66         0       0       0       1       1       1       1       1  \n",
       "..       ...     ...     ...     ...     ...     ...     ...     ...  \n",
       "220        0       0       0       0       0       0       0       0  \n",
       "221        0       0       0       0       0       0       0       0  \n",
       "222        0       0       0       0       0       0       0       0  \n",
       "223        0       0       0       0       0       0       0       0  \n",
       "224        0       0       0       0       0       0       0       0  \n",
       "\n",
       "[82 rows x 50 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data_Recovered[raw_data_Recovered['Country/Region'] == 'US']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1c647b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Shape of Cornirmed is:  (10350, 6)\n",
      "The Shape of Cornirmed is:  (10350, 6)\n",
      "The Shape of Cornirmed is:  (10350, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>Date</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anhui</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>31.8257</td>\n",
       "      <td>117.2264</td>\n",
       "      <td>1/22/20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beijing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>40.1824</td>\n",
       "      <td>116.4142</td>\n",
       "      <td>1/22/20</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chongqing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>30.0572</td>\n",
       "      <td>107.8740</td>\n",
       "      <td>1/22/20</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fujian</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>26.0789</td>\n",
       "      <td>117.9874</td>\n",
       "      <td>1/22/20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gansu</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>36.0611</td>\n",
       "      <td>103.8343</td>\n",
       "      <td>1/22/20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province/State  Country/Region      Lat      Long     Date  value\n",
       "0          Anhui  Mainland China  31.8257  117.2264  1/22/20      1\n",
       "1        Beijing  Mainland China  40.1824  116.4142  1/22/20     14\n",
       "2      Chongqing  Mainland China  30.0572  107.8740  1/22/20      6\n",
       "3         Fujian  Mainland China  26.0789  117.9874  1/22/20      1\n",
       "4          Gansu  Mainland China  36.0611  103.8343  1/22/20      0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dénormalisation des données\n",
    "\n",
    "raw_data_confirmed2 = pd.melt(raw_data_confirmed, id_vars=['Province/State', 'Country/Region', 'Lat', 'Long'], var_name=['Date'])\n",
    "raw_data_deaths2 = pd.melt(raw_data_deaths, id_vars=['Province/State', 'Country/Region', 'Lat', 'Long'], var_name=['Date'])\n",
    "raw_data_Recovered2 = pd.melt(raw_data_Recovered, id_vars=['Province/State', 'Country/Region', 'Lat', 'Long'], var_name=['Date'])\n",
    "\n",
    "\n",
    "print(\"The Shape of Cornirmed is: \", raw_data_confirmed2.shape)\n",
    "print(\"The Shape of Cornirmed is: \", raw_data_deaths2.shape)\n",
    "print(\"The Shape of Cornirmed is: \", raw_data_Recovered2.shape)\n",
    "\n",
    "\n",
    "raw_data_confirmed2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5c88ca97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_1148\\1082209914.py:3: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  raw_data_confirmed2['Date'] = pd.to_datetime(raw_data_confirmed2['Date'])\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_1148\\1082209914.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  raw_data_deaths2['Date'] = pd.to_datetime(raw_data_deaths2['Date'])\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_1148\\1082209914.py:5: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  raw_data_Recovered2['Date'] = pd.to_datetime(raw_data_Recovered2['Date'])\n"
     ]
    }
   ],
   "source": [
    "#Conversion de la nouvelle colonne en dates\n",
    "\n",
    "raw_data_confirmed2['Date'] = pd.to_datetime(raw_data_confirmed2['Date'])\n",
    "raw_data_deaths2['Date'] = pd.to_datetime(raw_data_deaths2['Date'])\n",
    "raw_data_Recovered2['Date'] = pd.to_datetime(raw_data_Recovered2['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1919aee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renomer les valeurs\n",
    "raw_data_confirmed2.columns = raw_data_confirmed2.columns.str.replace('value', 'Confirmed')\n",
    "raw_data_deaths2.columns = raw_data_deaths2.columns.str.replace('value', 'Deaths')\n",
    "raw_data_Recovered2.columns = raw_data_Recovered2.columns.str.replace('value', 'Recovered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2ad5e453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Province/State    4324\n",
       "Country/Region       0\n",
       "Lat                  0\n",
       "Long                 0\n",
       "Date                 0\n",
       "Recovered            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Investiguer les valleurs  NULLES \n",
    "raw_data_Recovered2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "817f560f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Province/State    0\n",
       "Country/Region    0\n",
       "Lat               0\n",
       "Long              0\n",
       "Date              0\n",
       "Confirmed         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Traitement des valeurs NULL\n",
    "\n",
    "raw_data_confirmed2['Province/State'].fillna(raw_data_confirmed2['Country/Region'], inplace=True)\n",
    "raw_data_deaths2['Province/State'].fillna(raw_data_deaths2['Country/Region'], inplace=True)\n",
    "raw_data_Recovered2['Province/State'].fillna(raw_data_Recovered2['Country/Region'], inplace=True)\n",
    "\n",
    "raw_data_confirmed2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b6838747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Shape of Cornirmed is:  (10350, 6)\n",
      "The Shape of Cornirmed is:  (10350, 6)\n",
      "The Shape of Cornirmed is:  (10350, 6)\n"
     ]
    }
   ],
   "source": [
    "# Impression des formes avant la jointure\n",
    "print(\"The Shape of Cornirmed is: \", raw_data_confirmed2.shape)\n",
    "print(\"The Shape of Cornirmed is: \", raw_data_deaths2.shape)\n",
    "print(\"The Shape of Cornirmed is: \", raw_data_Recovered2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9d749869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Province/State    0\n",
       "Country/Region    0\n",
       "Lat               0\n",
       "Long              0\n",
       "Date              0\n",
       "Recovered         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data_confirmed2.isnull().sum()\n",
    "raw_data_deaths2.isnull().sum()\n",
    "raw_data_Recovered2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6ddb4c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of first join:  (10350, 7)\n",
      "Shape of second join:  (10350, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>Date</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Recovered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anhui</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>31.8257</td>\n",
       "      <td>117.2264</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beijing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>40.1824</td>\n",
       "      <td>116.4142</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chongqing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>30.0572</td>\n",
       "      <td>107.8740</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fujian</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>26.0789</td>\n",
       "      <td>117.9874</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gansu</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>36.0611</td>\n",
       "      <td>103.8343</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province/State  Country/Region      Lat      Long       Date  Confirmed  \\\n",
       "0          Anhui  Mainland China  31.8257  117.2264 2020-01-22          1   \n",
       "1        Beijing  Mainland China  40.1824  116.4142 2020-01-22         14   \n",
       "2      Chongqing  Mainland China  30.0572  107.8740 2020-01-22          6   \n",
       "3         Fujian  Mainland China  26.0789  117.9874 2020-01-22          1   \n",
       "4          Gansu  Mainland China  36.0611  103.8343 2020-01-22          0   \n",
       "\n",
       "   Deaths  Recovered  \n",
       "0       0          0  \n",
       "1       0          0  \n",
       "2       0          0  \n",
       "3       0          0  \n",
       "4       0          0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Jointures complètes\n",
    "\n",
    "# Confirmed with Deaths\n",
    "full_join = raw_data_confirmed2.merge(raw_data_deaths2[['Province/State','Country/Region','Date','Deaths']], \n",
    "                                      how = 'left', \n",
    "                                      left_on = ['Province/State','Country/Region','Date'], \n",
    "                                      right_on = ['Province/State', 'Country/Region','Date'])\n",
    "\n",
    "print(\"Shape of first join: \", full_join.shape)\n",
    "\n",
    "# full join with Recovered\n",
    "full_join = full_join.merge(raw_data_Recovered2[['Province/State','Country/Region','Date','Recovered']], \n",
    "                                      how = 'left', \n",
    "                                      left_on = ['Province/State','Country/Region','Date'], \n",
    "                                      right_on = ['Province/State', 'Country/Region','Date'])\n",
    "\n",
    "print(\"Shape of second join: \", full_join.shape)\n",
    "\n",
    "full_join.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6c797feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Province/State    0\n",
       "Country/Region    0\n",
       "Lat               0\n",
       "Long              0\n",
       "Date              0\n",
       "Confirmed         0\n",
       "Deaths            0\n",
       "Recovered         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for null values (especially long and lat)\n",
    "full_join.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1000868c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>Date</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Recovered</th>\n",
       "      <th>Month-Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anhui</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>31.8257</td>\n",
       "      <td>117.2264</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Jan-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beijing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>40.1824</td>\n",
       "      <td>116.4142</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Jan-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chongqing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>30.0572</td>\n",
       "      <td>107.8740</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Jan-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fujian</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>26.0789</td>\n",
       "      <td>117.9874</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Jan-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gansu</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>36.0611</td>\n",
       "      <td>103.8343</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Jan-2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province/State  Country/Region      Lat      Long       Date  Confirmed  \\\n",
       "0          Anhui  Mainland China  31.8257  117.2264 2020-01-22          1   \n",
       "1        Beijing  Mainland China  40.1824  116.4142 2020-01-22         14   \n",
       "2      Chongqing  Mainland China  30.0572  107.8740 2020-01-22          6   \n",
       "3         Fujian  Mainland China  26.0789  117.9874 2020-01-22          1   \n",
       "4          Gansu  Mainland China  36.0611  103.8343 2020-01-22          0   \n",
       "\n",
       "   Deaths  Recovered Month-Year  \n",
       "0       0          0   Jan-2020  \n",
       "1       0          0   Jan-2020  \n",
       "2       0          0   Jan-2020  \n",
       "3       0          0   Jan-2020  \n",
       "4       0          0   Jan-2020  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding Month and Year as a new Column\n",
    "full_join['Month-Year'] = full_join['Date'].dt.strftime('%b-%Y')\n",
    "full_join.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f222f201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>Date</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Recovered</th>\n",
       "      <th>Month-Year</th>\n",
       "      <th>Confirmed - 1</th>\n",
       "      <th>Deaths - 1</th>\n",
       "      <th>Recovered - 1</th>\n",
       "      <th>Date - 1</th>\n",
       "      <th>Date Minus 1</th>\n",
       "      <th>Confirmed Daily</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anhui</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>31.8257</td>\n",
       "      <td>117.2264</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Jan-2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anhui</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>31.8257</td>\n",
       "      <td>117.2264</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Jan-2020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anhui</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>31.8257</td>\n",
       "      <td>117.2264</td>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Jan-2020</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anhui</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>31.8257</td>\n",
       "      <td>117.2264</td>\n",
       "      <td>2020-01-25</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Jan-2020</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-01-25</td>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anhui</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>31.8257</td>\n",
       "      <td>117.2264</td>\n",
       "      <td>2020-01-26</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Jan-2020</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-01-26</td>\n",
       "      <td>2020-01-25</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province/State  Country/Region      Lat      Long       Date  Confirmed  \\\n",
       "0          Anhui  Mainland China  31.8257  117.2264 2020-01-22        1.0   \n",
       "1          Anhui  Mainland China  31.8257  117.2264 2020-01-23        9.0   \n",
       "2          Anhui  Mainland China  31.8257  117.2264 2020-01-24       15.0   \n",
       "3          Anhui  Mainland China  31.8257  117.2264 2020-01-25       39.0   \n",
       "4          Anhui  Mainland China  31.8257  117.2264 2020-01-26       60.0   \n",
       "\n",
       "   Deaths  Recovered Month-Year  Confirmed - 1  Deaths - 1  Recovered - 1  \\\n",
       "0     0.0        0.0   Jan-2020            NaN         NaN            NaN   \n",
       "1     0.0        0.0   Jan-2020            1.0         0.0            0.0   \n",
       "2     0.0        0.0   Jan-2020            9.0         0.0            0.0   \n",
       "3     0.0        0.0   Jan-2020           15.0         0.0            0.0   \n",
       "4     0.0        0.0   Jan-2020           39.0         0.0            0.0   \n",
       "\n",
       "    Date - 1 Date Minus 1  Confirmed Daily  \n",
       "0        NaT          NaT              NaN  \n",
       "1 2020-01-23   2020-01-22              8.0  \n",
       "2 2020-01-24   2020-01-23              6.0  \n",
       "3 2020-01-25   2020-01-24             24.0  \n",
       "4 2020-01-26   2020-01-25             21.0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######################## Braking the numbers by Day #########################################\n",
    "#############################################################################################\n",
    "\n",
    "# filtering data to Anhui to give you an example\n",
    "\n",
    "#creating a new df    \n",
    "test = full_join[full_join['Province/State'] == 'Anhui']\n",
    "\n",
    "#creating a new df    \n",
    "full_join2 = test.copy()\n",
    "\n",
    "#creating a new date columns - 1\n",
    "full_join2['Date - 1'] = full_join2['Date'] + pd.Timedelta(days=1)\n",
    "full_join2.rename(columns={'Confirmed': 'Confirmed - 1', 'Deaths': 'Deaths - 1', 'Recovered': 'Recovered - 1',\n",
    "                          'Date': 'Date Minus 1'}, inplace=True)\n",
    "\n",
    "#Joing on the 2 DFs\n",
    "full_join3 = test.merge(full_join2[['Province/State', 'Country/Region','Confirmed - 1', 'Deaths - 1', \n",
    "                            'Recovered - 1', 'Date - 1', 'Date Minus 1']], how = 'outer',\n",
    "                             left_on = ['Province/State','Country/Region','Date'], \n",
    "                             right_on = ['Province/State', 'Country/Region','Date - 1'])\n",
    "\n",
    "# Additional Calculations\n",
    "full_join3['Confirmed Daily'] = full_join3['Confirmed'] - full_join3['Confirmed - 1']\n",
    "\n",
    "\n",
    "test.head()\n",
    "full_join2.head()\n",
    "full_join3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "89c6fda3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>Date</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Recovered</th>\n",
       "      <th>Month-Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anhui</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>31.8257</td>\n",
       "      <td>117.2264</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Jan-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>Anhui</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>31.8257</td>\n",
       "      <td>117.2264</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Jan-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>Anhui</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>31.8257</td>\n",
       "      <td>117.2264</td>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Jan-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>Anhui</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>31.8257</td>\n",
       "      <td>117.2264</td>\n",
       "      <td>2020-01-25</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Jan-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>Anhui</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>31.8257</td>\n",
       "      <td>117.2264</td>\n",
       "      <td>2020-01-26</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Jan-2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Province/State  Country/Region      Lat      Long       Date  Confirmed  \\\n",
       "0            Anhui  Mainland China  31.8257  117.2264 2020-01-22          1   \n",
       "225          Anhui  Mainland China  31.8257  117.2264 2020-01-23          9   \n",
       "450          Anhui  Mainland China  31.8257  117.2264 2020-01-24         15   \n",
       "675          Anhui  Mainland China  31.8257  117.2264 2020-01-25         39   \n",
       "900          Anhui  Mainland China  31.8257  117.2264 2020-01-26         60   \n",
       "\n",
       "     Deaths  Recovered Month-Year  \n",
       "0         0          0   Jan-2020  \n",
       "225       0          0   Jan-2020  \n",
       "450       0          0   Jan-2020  \n",
       "675       0          0   Jan-2020  \n",
       "900       0          0   Jan-2020  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1c36858e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>Date Minus 1</th>\n",
       "      <th>Confirmed - 1</th>\n",
       "      <th>Deaths - 1</th>\n",
       "      <th>Recovered - 1</th>\n",
       "      <th>Month-Year</th>\n",
       "      <th>Date - 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anhui</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>31.8257</td>\n",
       "      <td>117.2264</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Jan-2020</td>\n",
       "      <td>2020-01-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>Anhui</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>31.8257</td>\n",
       "      <td>117.2264</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Jan-2020</td>\n",
       "      <td>2020-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>Anhui</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>31.8257</td>\n",
       "      <td>117.2264</td>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Jan-2020</td>\n",
       "      <td>2020-01-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>Anhui</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>31.8257</td>\n",
       "      <td>117.2264</td>\n",
       "      <td>2020-01-25</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Jan-2020</td>\n",
       "      <td>2020-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>Anhui</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>31.8257</td>\n",
       "      <td>117.2264</td>\n",
       "      <td>2020-01-26</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Jan-2020</td>\n",
       "      <td>2020-01-27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Province/State  Country/Region      Lat      Long Date Minus 1  \\\n",
       "0            Anhui  Mainland China  31.8257  117.2264   2020-01-22   \n",
       "225          Anhui  Mainland China  31.8257  117.2264   2020-01-23   \n",
       "450          Anhui  Mainland China  31.8257  117.2264   2020-01-24   \n",
       "675          Anhui  Mainland China  31.8257  117.2264   2020-01-25   \n",
       "900          Anhui  Mainland China  31.8257  117.2264   2020-01-26   \n",
       "\n",
       "     Confirmed - 1  Deaths - 1  Recovered - 1 Month-Year   Date - 1  \n",
       "0                1           0              0   Jan-2020 2020-01-23  \n",
       "225              9           0              0   Jan-2020 2020-01-24  \n",
       "450             15           0              0   Jan-2020 2020-01-25  \n",
       "675             39           0              0   Jan-2020 2020-01-26  \n",
       "900             60           0              0   Jan-2020 2020-01-27  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_join2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0ab1c845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10350, 17)\n"
     ]
    }
   ],
   "source": [
    "######################## Braking the numbers by Day #########################################\n",
    "#############################################################################################\n",
    "\n",
    "## Applying it on all dataset\n",
    "\n",
    "#creating a new df    \n",
    "full_join2 = full_join.copy()\n",
    "\n",
    "#creating a new date columns - 1\n",
    "full_join2['Date - 1'] = full_join2['Date'] + pd.Timedelta(days=1)\n",
    "full_join2.rename(columns={'Confirmed': 'Confirmed - 1', 'Deaths': 'Deaths - 1', 'Recovered': 'Recovered - 1',\n",
    "                          'Date': 'Date Minus 1'}, inplace=True)\n",
    "\n",
    "#Joing on the 2 DFs\n",
    "full_join3 = full_join.merge(full_join2[['Province/State', 'Country/Region','Confirmed - 1', 'Deaths - 1', \n",
    "                            'Recovered - 1', 'Date - 1', 'Date Minus 1']], how = 'left',\n",
    "                             left_on = ['Province/State','Country/Region','Date'], \n",
    "                             right_on = ['Province/State', 'Country/Region','Date - 1'])\n",
    "\n",
    "#minus_onedf.rename(columns={'Confirmed': 'Confirmed - 1', 'Deaths': 'Deaths - 1', 'Recovered': 'Recovered - 1'}, inplace=True)\n",
    "\n",
    "full_join3.head()\n",
    "\n",
    "# Additional Calculations\n",
    "full_join3['Confirmed Daily'] = full_join3['Confirmed'] - full_join3['Confirmed - 1']\n",
    "full_join3['Deaths Daily'] = full_join3['Deaths'] - full_join3['Deaths - 1']\n",
    "full_join3['Recovered Daily'] = full_join3['Recovered'] - full_join3['Recovered - 1']\n",
    "\n",
    "print(full_join3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "444c844f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>Date</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Recovered</th>\n",
       "      <th>Month-Year</th>\n",
       "      <th>Confirmed - 1</th>\n",
       "      <th>Deaths - 1</th>\n",
       "      <th>Recovered - 1</th>\n",
       "      <th>Date - 1</th>\n",
       "      <th>Date Minus 1</th>\n",
       "      <th>Confirmed Daily</th>\n",
       "      <th>Deaths Daily</th>\n",
       "      <th>Recovered Daily</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anhui</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>31.8257</td>\n",
       "      <td>117.2264</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Jan-2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beijing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>40.1824</td>\n",
       "      <td>116.4142</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Jan-2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chongqing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>30.0572</td>\n",
       "      <td>107.8740</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Jan-2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fujian</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>26.0789</td>\n",
       "      <td>117.9874</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Jan-2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gansu</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>36.0611</td>\n",
       "      <td>103.8343</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Jan-2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province/State  Country/Region      Lat      Long       Date  Confirmed  \\\n",
       "0          Anhui  Mainland China  31.8257  117.2264 2020-01-22          1   \n",
       "1        Beijing  Mainland China  40.1824  116.4142 2020-01-22         14   \n",
       "2      Chongqing  Mainland China  30.0572  107.8740 2020-01-22          6   \n",
       "3         Fujian  Mainland China  26.0789  117.9874 2020-01-22          1   \n",
       "4          Gansu  Mainland China  36.0611  103.8343 2020-01-22          0   \n",
       "\n",
       "   Deaths  Recovered Month-Year  Confirmed - 1  Deaths - 1  Recovered - 1  \\\n",
       "0       0          0   Jan-2020            NaN         NaN            NaN   \n",
       "1       0          0   Jan-2020            NaN         NaN            NaN   \n",
       "2       0          0   Jan-2020            NaN         NaN            NaN   \n",
       "3       0          0   Jan-2020            NaN         NaN            NaN   \n",
       "4       0          0   Jan-2020            NaN         NaN            NaN   \n",
       "\n",
       "  Date - 1 Date Minus 1  Confirmed Daily  Deaths Daily  Recovered Daily  \n",
       "0      NaT          NaT              NaN           NaN              NaN  \n",
       "1      NaT          NaT              NaN           NaN              NaN  \n",
       "2      NaT          NaT              NaN           NaN              NaN  \n",
       "3      NaT          NaT              NaN           NaN              NaN  \n",
       "4      NaT          NaT              NaN           NaN              NaN  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_join3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f113b98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_1148\\2712811409.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  full_join3['Confirmed Daily'].loc[full_join3['Date'] == '2020-01-22'] = full_join3['Confirmed']\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_1148\\2712811409.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  full_join3['Deaths Daily'].loc[full_join3['Date'] == '2020-01-22'] = full_join3['Deaths']\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_1148\\2712811409.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  full_join3['Recovered Daily'].loc[full_join3['Date'] == '2020-01-22'] = full_join3['Recovered']\n"
     ]
    }
   ],
   "source": [
    "# Additing manually the numbers for first day\n",
    "\n",
    "full_join3['Confirmed Daily'].loc[full_join3['Date'] == '2020-01-22'] = full_join3['Confirmed']\n",
    "full_join3['Deaths Daily'].loc[full_join3['Date'] == '2020-01-22'] = full_join3['Deaths']\n",
    "full_join3['Recovered Daily'].loc[full_join3['Date'] == '2020-01-22'] = full_join3['Recovered']\n",
    "\n",
    "# deleting columns\n",
    "del full_join3['Confirmed - 1']\n",
    "del full_join3['Deaths - 1']\n",
    "del full_join3['Recovered - 1']\n",
    "del full_join3['Date - 1']\n",
    "del full_join3['Date Minus 1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "743003ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_1148\\513156660.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  full_join3['Hubei Vs Rest of the World'].loc[full_join3['Province/State'] == 'Hubei'] = 'Hubei - Virus birth'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>Date</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Recovered</th>\n",
       "      <th>Month-Year</th>\n",
       "      <th>Confirmed Daily</th>\n",
       "      <th>Deaths Daily</th>\n",
       "      <th>Recovered Daily</th>\n",
       "      <th>Hubei Vs Rest of the World</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anhui</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>31.8257</td>\n",
       "      <td>117.2264</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Jan-2020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Rest of the World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beijing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>40.1824</td>\n",
       "      <td>116.4142</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Jan-2020</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Rest of the World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chongqing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>30.0572</td>\n",
       "      <td>107.8740</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Jan-2020</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Rest of the World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fujian</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>26.0789</td>\n",
       "      <td>117.9874</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Jan-2020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Rest of the World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gansu</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>36.0611</td>\n",
       "      <td>103.8343</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Jan-2020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Rest of the World</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province/State  Country/Region      Lat      Long       Date  Confirmed  \\\n",
       "0          Anhui  Mainland China  31.8257  117.2264 2020-01-22          1   \n",
       "1        Beijing  Mainland China  40.1824  116.4142 2020-01-22         14   \n",
       "2      Chongqing  Mainland China  30.0572  107.8740 2020-01-22          6   \n",
       "3         Fujian  Mainland China  26.0789  117.9874 2020-01-22          1   \n",
       "4          Gansu  Mainland China  36.0611  103.8343 2020-01-22          0   \n",
       "\n",
       "   Deaths  Recovered Month-Year  Confirmed Daily  Deaths Daily  \\\n",
       "0       0          0   Jan-2020              1.0           0.0   \n",
       "1       0          0   Jan-2020             14.0           0.0   \n",
       "2       0          0   Jan-2020              6.0           0.0   \n",
       "3       0          0   Jan-2020              1.0           0.0   \n",
       "4       0          0   Jan-2020              0.0           0.0   \n",
       "\n",
       "   Recovered Daily Hubei Vs Rest of the World  \n",
       "0              0.0          Rest of the World  \n",
       "1              0.0          Rest of the World  \n",
       "2              0.0          Rest of the World  \n",
       "3              0.0          Rest of the World  \n",
       "4              0.0          Rest of the World  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating additional slicer for easy of use\n",
    "\n",
    "full_join3['Hubei Vs Rest of the World'] = 'Rest of the World'\n",
    "full_join3['Hubei Vs Rest of the World'].loc[full_join3['Province/State'] == 'Hubei'] = 'Hubei - Virus birth'\n",
    "\n",
    "#full_join3[full_join3['Province/State'] == 'Hubei']\n",
    "full_join3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d6656560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting the data\n",
    "\n",
    "# Setting my path\n",
    "path = \"C:\\\\Users\\\\dell\\\\Desktop\\\\data vis\"\n",
    "\n",
    "# Changing my CWD\n",
    "os.chdir(path)\n",
    "\n",
    "full_join3.to_csv('CoronaVirus PowerBI Raw', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7a435500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>Date</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Recovered</th>\n",
       "      <th>Month-Year</th>\n",
       "      <th>Confirmed Daily</th>\n",
       "      <th>Deaths Daily</th>\n",
       "      <th>Recovered Daily</th>\n",
       "      <th>Hubei Vs Rest of the World</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anhui</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>31.8257</td>\n",
       "      <td>117.2264</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Jan-2020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Rest of the World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beijing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>40.1824</td>\n",
       "      <td>116.4142</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Jan-2020</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Rest of the World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chongqing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>30.0572</td>\n",
       "      <td>107.8740</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Jan-2020</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Rest of the World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fujian</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>26.0789</td>\n",
       "      <td>117.9874</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Jan-2020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Rest of the World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gansu</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>36.0611</td>\n",
       "      <td>103.8343</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Jan-2020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Rest of the World</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province/State  Country/Region      Lat      Long       Date  Confirmed  \\\n",
       "0          Anhui  Mainland China  31.8257  117.2264 2020-01-22          1   \n",
       "1        Beijing  Mainland China  40.1824  116.4142 2020-01-22         14   \n",
       "2      Chongqing  Mainland China  30.0572  107.8740 2020-01-22          6   \n",
       "3         Fujian  Mainland China  26.0789  117.9874 2020-01-22          1   \n",
       "4          Gansu  Mainland China  36.0611  103.8343 2020-01-22          0   \n",
       "\n",
       "   Deaths  Recovered Month-Year  Confirmed Daily  Deaths Daily  \\\n",
       "0       0          0   Jan-2020              1.0           0.0   \n",
       "1       0          0   Jan-2020             14.0           0.0   \n",
       "2       0          0   Jan-2020              6.0           0.0   \n",
       "3       0          0   Jan-2020              1.0           0.0   \n",
       "4       0          0   Jan-2020              0.0           0.0   \n",
       "\n",
       "   Recovered Daily Hubei Vs Rest of the World  \n",
       "0              0.0          Rest of the World  \n",
       "1              0.0          Rest of the World  \n",
       "2              0.0          Rest of the World  \n",
       "3              0.0          Rest of the World  \n",
       "4              0.0          Rest of the World  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_join3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2609289c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10350, 13)\n",
      "2020-01-22 00:00:00\n",
      "2020-01-23 00:00:00\n",
      "<DatetimeArray>\n",
      "['2020-01-22 00:00:00', '2020-01-23 00:00:00']\n",
      "Length: 2, dtype: datetime64[ns]\n",
      "2020-01-24 00:00:00\n",
      "<DatetimeArray>\n",
      "['2020-01-22 00:00:00', '2020-01-23 00:00:00', '2020-01-24 00:00:00']\n",
      "Length: 3, dtype: datetime64[ns]\n",
      "2020-01-25 00:00:00\n",
      "<DatetimeArray>\n",
      "['2020-01-22 00:00:00', '2020-01-23 00:00:00', '2020-01-24 00:00:00',\n",
      " '2020-01-25 00:00:00']\n",
      "Length: 4, dtype: datetime64[ns]\n",
      "2020-01-26 00:00:00\n",
      "<DatetimeArray>\n",
      "['2020-01-22 00:00:00', '2020-01-23 00:00:00', '2020-01-24 00:00:00',\n",
      " '2020-01-25 00:00:00', '2020-01-26 00:00:00']\n",
      "Length: 5, dtype: datetime64[ns]\n",
      "2020-01-27 00:00:00\n",
      "<DatetimeArray>\n",
      "['2020-01-22 00:00:00', '2020-01-23 00:00:00', '2020-01-24 00:00:00',\n",
      " '2020-01-25 00:00:00', '2020-01-26 00:00:00', '2020-01-27 00:00:00']\n",
      "Length: 6, dtype: datetime64[ns]\n",
      "2020-01-28 00:00:00\n",
      "<DatetimeArray>\n",
      "['2020-01-22 00:00:00', '2020-01-23 00:00:00', '2020-01-24 00:00:00',\n",
      " '2020-01-25 00:00:00', '2020-01-26 00:00:00', '2020-01-27 00:00:00',\n",
      " '2020-01-28 00:00:00']\n",
      "Length: 7, dtype: datetime64[ns]\n",
      "2020-01-29 00:00:00\n",
      "<DatetimeArray>\n",
      "['2020-01-22 00:00:00', '2020-01-23 00:00:00', '2020-01-24 00:00:00',\n",
      " '2020-01-25 00:00:00', '2020-01-26 00:00:00', '2020-01-27 00:00:00',\n",
      " '2020-01-28 00:00:00', '2020-01-29 00:00:00']\n",
      "Length: 8, dtype: datetime64[ns]\n",
      "2020-01-30 00:00:00\n",
      "<DatetimeArray>\n",
      "['2020-01-22 00:00:00', '2020-01-23 00:00:00', '2020-01-24 00:00:00',\n",
      " '2020-01-25 00:00:00', '2020-01-26 00:00:00', '2020-01-27 00:00:00',\n",
      " '2020-01-28 00:00:00', '2020-01-29 00:00:00', '2020-01-30 00:00:00']\n",
      "Length: 9, dtype: datetime64[ns]\n",
      "2020-01-31 00:00:00\n",
      "<DatetimeArray>\n",
      "['2020-01-22 00:00:00', '2020-01-23 00:00:00', '2020-01-24 00:00:00',\n",
      " '2020-01-25 00:00:00', '2020-01-26 00:00:00', '2020-01-27 00:00:00',\n",
      " '2020-01-28 00:00:00', '2020-01-29 00:00:00', '2020-01-30 00:00:00',\n",
      " '2020-01-31 00:00:00']\n",
      "Length: 10, dtype: datetime64[ns]\n",
      "2020-02-01 00:00:00\n",
      "<DatetimeArray>\n",
      "['2020-01-22 00:00:00', '2020-01-23 00:00:00', '2020-01-24 00:00:00',\n",
      " '2020-01-25 00:00:00', '2020-01-26 00:00:00', '2020-01-27 00:00:00',\n",
      " '2020-01-28 00:00:00', '2020-01-29 00:00:00', '2020-01-30 00:00:00',\n",
      " '2020-01-31 00:00:00', '2020-02-01 00:00:00']\n",
      "Length: 11, dtype: datetime64[ns]\n",
      "2020-02-02 00:00:00\n",
      "<DatetimeArray>\n",
      "['2020-01-22 00:00:00', '2020-01-23 00:00:00', '2020-01-24 00:00:00',\n",
      " '2020-01-25 00:00:00', '2020-01-26 00:00:00', '2020-01-27 00:00:00',\n",
      " '2020-01-28 00:00:00', '2020-01-29 00:00:00', '2020-01-30 00:00:00',\n",
      " '2020-01-31 00:00:00', '2020-02-01 00:00:00', '2020-02-02 00:00:00']\n",
      "Length: 12, dtype: datetime64[ns]\n",
      "2020-02-03 00:00:00\n",
      "<DatetimeArray>\n",
      "['2020-01-22 00:00:00', '2020-01-23 00:00:00', '2020-01-24 00:00:00',\n",
      " '2020-01-25 00:00:00', '2020-01-26 00:00:00', '2020-01-27 00:00:00',\n",
      " '2020-01-28 00:00:00', '2020-01-29 00:00:00', '2020-01-30 00:00:00',\n",
      " '2020-01-31 00:00:00', '2020-02-01 00:00:00', '2020-02-02 00:00:00',\n",
      " '2020-02-03 00:00:00']\n",
      "Length: 13, dtype: datetime64[ns]\n",
      "2020-02-04 00:00:00\n",
      "<DatetimeArray>\n",
      "['2020-01-22 00:00:00', '2020-01-23 00:00:00', '2020-01-24 00:00:00',\n",
      " '2020-01-25 00:00:00', '2020-01-26 00:00:00', '2020-01-27 00:00:00',\n",
      " '2020-01-28 00:00:00', '2020-01-29 00:00:00', '2020-01-30 00:00:00',\n",
      " '2020-01-31 00:00:00', '2020-02-01 00:00:00', '2020-02-02 00:00:00',\n",
      " '2020-02-03 00:00:00', '2020-02-04 00:00:00']\n",
      "Length: 14, dtype: datetime64[ns]\n",
      "2020-02-05 00:00:00\n",
      "<DatetimeArray>\n",
      "['2020-01-22 00:00:00', '2020-01-23 00:00:00', '2020-01-24 00:00:00',\n",
      " '2020-01-25 00:00:00', '2020-01-26 00:00:00', '2020-01-27 00:00:00',\n",
      " '2020-01-28 00:00:00', '2020-01-29 00:00:00', '2020-01-30 00:00:00',\n",
      " '2020-01-31 00:00:00', '2020-02-01 00:00:00', '2020-02-02 00:00:00',\n",
      " '2020-02-03 00:00:00', '2020-02-04 00:00:00', '2020-02-05 00:00:00']\n",
      "Length: 15, dtype: datetime64[ns]\n",
      "2020-02-06 00:00:00\n",
      "<DatetimeArray>\n",
      "['2020-01-22 00:00:00', '2020-01-23 00:00:00', '2020-01-24 00:00:00',\n",
      " '2020-01-25 00:00:00', '2020-01-26 00:00:00', '2020-01-27 00:00:00',\n",
      " '2020-01-28 00:00:00', '2020-01-29 00:00:00', '2020-01-30 00:00:00',\n",
      " '2020-01-31 00:00:00', '2020-02-01 00:00:00', '2020-02-02 00:00:00',\n",
      " '2020-02-03 00:00:00', '2020-02-04 00:00:00', '2020-02-05 00:00:00',\n",
      " '2020-02-06 00:00:00']\n",
      "Length: 16, dtype: datetime64[ns]\n",
      "2020-02-07 00:00:00\n",
      "<DatetimeArray>\n",
      "['2020-01-22 00:00:00', '2020-01-23 00:00:00', '2020-01-24 00:00:00',\n",
      " '2020-01-25 00:00:00', '2020-01-26 00:00:00', '2020-01-27 00:00:00',\n",
      " '2020-01-28 00:00:00', '2020-01-29 00:00:00', '2020-01-30 00:00:00',\n",
      " '2020-01-31 00:00:00', '2020-02-01 00:00:00', '2020-02-02 00:00:00',\n",
      " '2020-02-03 00:00:00', '2020-02-04 00:00:00', '2020-02-05 00:00:00',\n",
      " '2020-02-06 00:00:00', '2020-02-07 00:00:00']\n",
      "Length: 17, dtype: datetime64[ns]\n",
      "2020-02-08 00:00:00\n",
      "<DatetimeArray>\n",
      "['2020-01-22 00:00:00', '2020-01-23 00:00:00', '2020-01-24 00:00:00',\n",
      " '2020-01-25 00:00:00', '2020-01-26 00:00:00', '2020-01-27 00:00:00',\n",
      " '2020-01-28 00:00:00', '2020-01-29 00:00:00', '2020-01-30 00:00:00',\n",
      " '2020-01-31 00:00:00', '2020-02-01 00:00:00', '2020-02-02 00:00:00',\n",
      " '2020-02-03 00:00:00', '2020-02-04 00:00:00', '2020-02-05 00:00:00',\n",
      " '2020-02-06 00:00:00', '2020-02-07 00:00:00', '2020-02-08 00:00:00']\n",
      "Length: 18, dtype: datetime64[ns]\n",
      "2020-02-09 00:00:00\n",
      "<DatetimeArray>\n",
      "['2020-01-22 00:00:00', '2020-01-23 00:00:00', '2020-01-24 00:00:00',\n",
      " '2020-01-25 00:00:00', '2020-01-26 00:00:00', '2020-01-27 00:00:00',\n",
      " '2020-01-28 00:00:00', '2020-01-29 00:00:00', '2020-01-30 00:00:00',\n",
      " '2020-01-31 00:00:00', '2020-02-01 00:00:00', '2020-02-02 00:00:00',\n",
      " '2020-02-03 00:00:00', '2020-02-04 00:00:00', '2020-02-05 00:00:00',\n",
      " '2020-02-06 00:00:00', '2020-02-07 00:00:00', '2020-02-08 00:00:00',\n",
      " '2020-02-09 00:00:00']\n",
      "Length: 19, dtype: datetime64[ns]\n",
      "2020-02-10 00:00:00\n",
      "<DatetimeArray>\n",
      "['2020-01-22 00:00:00', '2020-01-23 00:00:00', '2020-01-24 00:00:00',\n",
      " '2020-01-25 00:00:00', '2020-01-26 00:00:00', '2020-01-27 00:00:00',\n",
      " '2020-01-28 00:00:00', '2020-01-29 00:00:00', '2020-01-30 00:00:00',\n",
      " '2020-01-31 00:00:00', '2020-02-01 00:00:00', '2020-02-02 00:00:00',\n",
      " '2020-02-03 00:00:00', '2020-02-04 00:00:00', '2020-02-05 00:00:00',\n",
      " '2020-02-06 00:00:00', '2020-02-07 00:00:00', '2020-02-08 00:00:00',\n",
      " '2020-02-09 00:00:00', '2020-02-10 00:00:00']\n",
      "Length: 20, dtype: datetime64[ns]\n",
      "2020-02-11 00:00:00\n",
      "<DatetimeArray>\n",
      "['2020-01-22 00:00:00', '2020-01-23 00:00:00', '2020-01-24 00:00:00',\n",
      " '2020-01-25 00:00:00', '2020-01-26 00:00:00', '2020-01-27 00:00:00',\n",
      " '2020-01-28 00:00:00', '2020-01-29 00:00:00', '2020-01-30 00:00:00',\n",
      " '2020-01-31 00:00:00', '2020-02-01 00:00:00', '2020-02-02 00:00:00',\n",
      " '2020-02-03 00:00:00', '2020-02-04 00:00:00', '2020-02-05 00:00:00',\n",
      " '2020-02-06 00:00:00', '2020-02-07 00:00:00', '2020-02-08 00:00:00',\n",
      " '2020-02-09 00:00:00', '2020-02-10 00:00:00', '2020-02-11 00:00:00']\n",
      "Length: 21, dtype: datetime64[ns]\n",
      "2020-02-12 00:00:00\n",
      "<DatetimeArray>\n",
      "['2020-01-22 00:00:00', '2020-01-23 00:00:00', '2020-01-24 00:00:00',\n",
      " '2020-01-25 00:00:00', '2020-01-26 00:00:00', '2020-01-27 00:00:00',\n",
      " '2020-01-28 00:00:00', '2020-01-29 00:00:00', '2020-01-30 00:00:00',\n",
      " '2020-01-31 00:00:00', '2020-02-01 00:00:00', '2020-02-02 00:00:00',\n",
      " '2020-02-03 00:00:00', '2020-02-04 00:00:00', '2020-02-05 00:00:00',\n",
      " '2020-02-06 00:00:00', '2020-02-07 00:00:00', '2020-02-08 00:00:00',\n",
      " '2020-02-09 00:00:00', '2020-02-10 00:00:00', '2020-02-11 00:00:00',\n",
      " '2020-02-12 00:00:00']\n",
      "Length: 22, dtype: datetime64[ns]\n",
      "2020-02-13 00:00:00\n",
      "<DatetimeArray>\n",
      "['2020-01-22 00:00:00', '2020-01-23 00:00:00', '2020-01-24 00:00:00',\n",
      " '2020-01-25 00:00:00', '2020-01-26 00:00:00', '2020-01-27 00:00:00',\n",
      " '2020-01-28 00:00:00', '2020-01-29 00:00:00', '2020-01-30 00:00:00',\n",
      " '2020-01-31 00:00:00', '2020-02-01 00:00:00', '2020-02-02 00:00:00',\n",
      " '2020-02-03 00:00:00', '2020-02-04 00:00:00', '2020-02-05 00:00:00',\n",
      " '2020-02-06 00:00:00', '2020-02-07 00:00:00', '2020-02-08 00:00:00',\n",
      " '2020-02-09 00:00:00', '2020-02-10 00:00:00', '2020-02-11 00:00:00',\n",
      " '2020-02-12 00:00:00', '2020-02-13 00:00:00']\n",
      "Length: 23, dtype: datetime64[ns]\n",
      "2020-02-14 00:00:00\n",
      "<DatetimeArray>\n",
      "['2020-01-22 00:00:00', '2020-01-23 00:00:00', '2020-01-24 00:00:00',\n",
      " '2020-01-25 00:00:00', '2020-01-26 00:00:00', '2020-01-27 00:00:00',\n",
      " '2020-01-28 00:00:00', '2020-01-29 00:00:00', '2020-01-30 00:00:00',\n",
      " '2020-01-31 00:00:00', '2020-02-01 00:00:00', '2020-02-02 00:00:00',\n",
      " '2020-02-03 00:00:00', '2020-02-04 00:00:00', '2020-02-05 00:00:00',\n",
      " '2020-02-06 00:00:00', '2020-02-07 00:00:00', '2020-02-08 00:00:00',\n",
      " '2020-02-09 00:00:00', '2020-02-10 00:00:00', '2020-02-11 00:00:00',\n",
      " '2020-02-12 00:00:00', '2020-02-13 00:00:00', '2020-02-14 00:00:00']\n",
      "Length: 24, dtype: datetime64[ns]\n",
      "2020-02-15 00:00:00\n",
      "<DatetimeArray>\n",
      "['2020-01-22 00:00:00', '2020-01-23 00:00:00', '2020-01-24 00:00:00',\n",
      " '2020-01-25 00:00:00', '2020-01-26 00:00:00', '2020-01-27 00:00:00',\n",
      " '2020-01-28 00:00:00', '2020-01-29 00:00:00', '2020-01-30 00:00:00',\n",
      " '2020-01-31 00:00:00', '2020-02-01 00:00:00', '2020-02-02 00:00:00',\n",
      " '2020-02-03 00:00:00', '2020-02-04 00:00:00', '2020-02-05 00:00:00',\n",
      " '2020-02-06 00:00:00', '2020-02-07 00:00:00', '2020-02-08 00:00:00',\n",
      " '2020-02-09 00:00:00', '2020-02-10 00:00:00', '2020-02-11 00:00:00',\n",
      " '2020-02-12 00:00:00', '2020-02-13 00:00:00', '2020-02-14 00:00:00',\n",
      " '2020-02-15 00:00:00']\n",
      "Length: 25, dtype: datetime64[ns]\n",
      "2020-02-16 00:00:00\n",
      "<DatetimeArray>\n",
      "['2020-01-22 00:00:00', '2020-01-23 00:00:00', '2020-01-24 00:00:00',\n",
      " '2020-01-25 00:00:00', '2020-01-26 00:00:00', '2020-01-27 00:00:00',\n",
      " '2020-01-28 00:00:00', '2020-01-29 00:00:00', '2020-01-30 00:00:00',\n",
      " '2020-01-31 00:00:00', '2020-02-01 00:00:00', '2020-02-02 00:00:00',\n",
      " '2020-02-03 00:00:00', '2020-02-04 00:00:00', '2020-02-05 00:00:00',\n",
      " '2020-02-06 00:00:00', '2020-02-07 00:00:00', '2020-02-08 00:00:00',\n",
      " '2020-02-09 00:00:00', '2020-02-10 00:00:00', '2020-02-11 00:00:00',\n",
      " '2020-02-12 00:00:00', '2020-02-13 00:00:00', '2020-02-14 00:00:00',\n",
      " '2020-02-15 00:00:00', '2020-02-16 00:00:00']\n",
      "Length: 26, dtype: datetime64[ns]\n",
      "2020-02-17 00:00:00\n",
      "<DatetimeArray>\n",
      "['2020-01-22 00:00:00', '2020-01-23 00:00:00', '2020-01-24 00:00:00',\n",
      " '2020-01-25 00:00:00', '2020-01-26 00:00:00', '2020-01-27 00:00:00',\n",
      " '2020-01-28 00:00:00', '2020-01-29 00:00:00', '2020-01-30 00:00:00',\n",
      " '2020-01-31 00:00:00', '2020-02-01 00:00:00', '2020-02-02 00:00:00',\n",
      " '2020-02-03 00:00:00', '2020-02-04 00:00:00', '2020-02-05 00:00:00',\n",
      " '2020-02-06 00:00:00', '2020-02-07 00:00:00', '2020-02-08 00:00:00',\n",
      " '2020-02-09 00:00:00', '2020-02-10 00:00:00', '2020-02-11 00:00:00',\n",
      " '2020-02-12 00:00:00', '2020-02-13 00:00:00', '2020-02-14 00:00:00',\n",
      " '2020-02-15 00:00:00', '2020-02-16 00:00:00', '2020-02-17 00:00:00']\n",
      "Length: 27, dtype: datetime64[ns]\n",
      "2020-02-18 00:00:00\n",
      "<DatetimeArray>\n",
      "['2020-01-22 00:00:00', '2020-01-23 00:00:00', '2020-01-24 00:00:00',\n",
      " '2020-01-25 00:00:00', '2020-01-26 00:00:00', '2020-01-27 00:00:00',\n",
      " '2020-01-28 00:00:00', '2020-01-29 00:00:00', '2020-01-30 00:00:00',\n",
      " '2020-01-31 00:00:00', '2020-02-01 00:00:00', '2020-02-02 00:00:00',\n",
      " '2020-02-03 00:00:00', '2020-02-04 00:00:00', '2020-02-05 00:00:00',\n",
      " '2020-02-06 00:00:00', '2020-02-07 00:00:00', '2020-02-08 00:00:00',\n",
      " '2020-02-09 00:00:00', '2020-02-10 00:00:00', '2020-02-11 00:00:00',\n",
      " '2020-02-12 00:00:00', '2020-02-13 00:00:00', '2020-02-14 00:00:00',\n",
      " '2020-02-15 00:00:00', '2020-02-16 00:00:00', '2020-02-17 00:00:00',\n",
      " '2020-02-18 00:00:00']\n",
      "Length: 28, dtype: datetime64[ns]\n",
      "2020-02-19 00:00:00\n",
      "<DatetimeArray>\n",
      "['2020-01-22 00:00:00', '2020-01-23 00:00:00', '2020-01-24 00:00:00',\n",
      " '2020-01-25 00:00:00', '2020-01-26 00:00:00', '2020-01-27 00:00:00',\n",
      " '2020-01-28 00:00:00', '2020-01-29 00:00:00', '2020-01-30 00:00:00',\n",
      " '2020-01-31 00:00:00', '2020-02-01 00:00:00', '2020-02-02 00:00:00',\n",
      " '2020-02-03 00:00:00', '2020-02-04 00:00:00', '2020-02-05 00:00:00',\n",
      " '2020-02-06 00:00:00', '2020-02-07 00:00:00', '2020-02-08 00:00:00',\n",
      " '2020-02-09 00:00:00', '2020-02-10 00:00:00', '2020-02-11 00:00:00',\n",
      " '2020-02-12 00:00:00', '2020-02-13 00:00:00', '2020-02-14 00:00:00',\n",
      " '2020-02-15 00:00:00', '2020-02-16 00:00:00', '2020-02-17 00:00:00',\n",
      " '2020-02-18 00:00:00', '2020-02-19 00:00:00']\n",
      "Length: 29, dtype: datetime64[ns]\n",
      "2020-02-20 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_1148\\3429718920.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_data['Cumulative Date'] = i\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_1148\\3429718920.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_data['Cumulative Date'] = i\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_1148\\3429718920.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_data['Cumulative Date'] = i\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_1148\\3429718920.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_data['Cumulative Date'] = i\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_1148\\3429718920.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_data['Cumulative Date'] = i\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_1148\\3429718920.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_data['Cumulative Date'] = i\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_1148\\3429718920.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_data['Cumulative Date'] = i\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_1148\\3429718920.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_data['Cumulative Date'] = i\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_1148\\3429718920.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_data['Cumulative Date'] = i\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_1148\\3429718920.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_data['Cumulative Date'] = i\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_1148\\3429718920.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_data['Cumulative Date'] = i\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_1148\\3429718920.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_data['Cumulative Date'] = i\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_1148\\3429718920.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_data['Cumulative Date'] = i\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_1148\\3429718920.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_data['Cumulative Date'] = i\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_1148\\3429718920.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_data['Cumulative Date'] = i\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_1148\\3429718920.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_data['Cumulative Date'] = i\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_1148\\3429718920.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_data['Cumulative Date'] = i\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_1148\\3429718920.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_data['Cumulative Date'] = i\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_1148\\3429718920.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_data['Cumulative Date'] = i\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_1148\\3429718920.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_data['Cumulative Date'] = i\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_1148\\3429718920.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_data['Cumulative Date'] = i\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_1148\\3429718920.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_data['Cumulative Date'] = i\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_1148\\3429718920.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_data['Cumulative Date'] = i\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_1148\\3429718920.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_data['Cumulative Date'] = i\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_1148\\3429718920.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_data['Cumulative Date'] = i\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_1148\\3429718920.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_data['Cumulative Date'] = i\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_1148\\3429718920.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_data['Cumulative Date'] = i\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_1148\\3429718920.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_data['Cumulative Date'] = i\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_1148\\3429718920.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_data['Cumulative Date'] = i\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_1148\\3429718920.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_data['Cumulative Date'] = i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<DatetimeArray>\n",
      "['2020-01-22 00:00:00', '2020-01-23 00:00:00', '2020-01-24 00:00:00',\n",
      " '2020-01-25 00:00:00', '2020-01-26 00:00:00', '2020-01-27 00:00:00',\n",
      " '2020-01-28 00:00:00', '2020-01-29 00:00:00', '2020-01-30 00:00:00',\n",
      " '2020-01-31 00:00:00', '2020-02-01 00:00:00', '2020-02-02 00:00:00',\n",
      " '2020-02-03 00:00:00', '2020-02-04 00:00:00', '2020-02-05 00:00:00',\n",
      " '2020-02-06 00:00:00', '2020-02-07 00:00:00', '2020-02-08 00:00:00',\n",
      " '2020-02-09 00:00:00', '2020-02-10 00:00:00', '2020-02-11 00:00:00',\n",
      " '2020-02-12 00:00:00', '2020-02-13 00:00:00', '2020-02-14 00:00:00',\n",
      " '2020-02-15 00:00:00', '2020-02-16 00:00:00', '2020-02-17 00:00:00',\n",
      " '2020-02-18 00:00:00', '2020-02-19 00:00:00', '2020-02-20 00:00:00']\n",
      "Length: 30, dtype: datetime64[ns]\n",
      "2020-02-21 00:00:00\n",
      "<DatetimeArray>\n",
      "['2020-01-22 00:00:00', '2020-01-23 00:00:00', '2020-01-24 00:00:00',\n",
      " '2020-01-25 00:00:00', '2020-01-26 00:00:00', '2020-01-27 00:00:00',\n",
      " '2020-01-28 00:00:00', '2020-01-29 00:00:00', '2020-01-30 00:00:00',\n",
      " '2020-01-31 00:00:00', '2020-02-01 00:00:00', '2020-02-02 00:00:00',\n",
      " '2020-02-03 00:00:00', '2020-02-04 00:00:00', '2020-02-05 00:00:00',\n",
      " '2020-02-06 00:00:00', '2020-02-07 00:00:00', '2020-02-08 00:00:00',\n",
      " '2020-02-09 00:00:00', '2020-02-10 00:00:00', '2020-02-11 00:00:00',\n",
      " '2020-02-12 00:00:00', '2020-02-13 00:00:00', '2020-02-14 00:00:00',\n",
      " '2020-02-15 00:00:00', '2020-02-16 00:00:00', '2020-02-17 00:00:00',\n",
      " '2020-02-18 00:00:00', '2020-02-19 00:00:00', '2020-02-20 00:00:00',\n",
      " '2020-02-21 00:00:00']\n",
      "Length: 31, dtype: datetime64[ns]\n",
      "2020-02-22 00:00:00\n",
      "<DatetimeArray>\n",
      "['2020-01-22 00:00:00', '2020-01-23 00:00:00', '2020-01-24 00:00:00',\n",
      " '2020-01-25 00:00:00', '2020-01-26 00:00:00', '2020-01-27 00:00:00',\n",
      " '2020-01-28 00:00:00', '2020-01-29 00:00:00', '2020-01-30 00:00:00',\n",
      " '2020-01-31 00:00:00', '2020-02-01 00:00:00', '2020-02-02 00:00:00',\n",
      " '2020-02-03 00:00:00', '2020-02-04 00:00:00', '2020-02-05 00:00:00',\n",
      " '2020-02-06 00:00:00', '2020-02-07 00:00:00', '2020-02-08 00:00:00',\n",
      " '2020-02-09 00:00:00', '2020-02-10 00:00:00', '2020-02-11 00:00:00',\n",
      " '2020-02-12 00:00:00', '2020-02-13 00:00:00', '2020-02-14 00:00:00',\n",
      " '2020-02-15 00:00:00', '2020-02-16 00:00:00', '2020-02-17 00:00:00',\n",
      " '2020-02-18 00:00:00', '2020-02-19 00:00:00', '2020-02-20 00:00:00',\n",
      " '2020-02-21 00:00:00', '2020-02-22 00:00:00']\n",
      "Length: 32, dtype: datetime64[ns]\n",
      "2020-02-23 00:00:00\n",
      "<DatetimeArray>\n",
      "['2020-01-22 00:00:00', '2020-01-23 00:00:00', '2020-01-24 00:00:00',\n",
      " '2020-01-25 00:00:00', '2020-01-26 00:00:00', '2020-01-27 00:00:00',\n",
      " '2020-01-28 00:00:00', '2020-01-29 00:00:00', '2020-01-30 00:00:00',\n",
      " '2020-01-31 00:00:00', '2020-02-01 00:00:00', '2020-02-02 00:00:00',\n",
      " '2020-02-03 00:00:00', '2020-02-04 00:00:00', '2020-02-05 00:00:00',\n",
      " '2020-02-06 00:00:00', '2020-02-07 00:00:00', '2020-02-08 00:00:00',\n",
      " '2020-02-09 00:00:00', '2020-02-10 00:00:00', '2020-02-11 00:00:00',\n",
      " '2020-02-12 00:00:00', '2020-02-13 00:00:00', '2020-02-14 00:00:00',\n",
      " '2020-02-15 00:00:00', '2020-02-16 00:00:00', '2020-02-17 00:00:00',\n",
      " '2020-02-18 00:00:00', '2020-02-19 00:00:00', '2020-02-20 00:00:00',\n",
      " '2020-02-21 00:00:00', '2020-02-22 00:00:00', '2020-02-23 00:00:00']\n",
      "Length: 33, dtype: datetime64[ns]\n",
      "2020-02-24 00:00:00\n",
      "<DatetimeArray>\n",
      "['2020-01-22 00:00:00', '2020-01-23 00:00:00', '2020-01-24 00:00:00',\n",
      " '2020-01-25 00:00:00', '2020-01-26 00:00:00', '2020-01-27 00:00:00',\n",
      " '2020-01-28 00:00:00', '2020-01-29 00:00:00', '2020-01-30 00:00:00',\n",
      " '2020-01-31 00:00:00', '2020-02-01 00:00:00', '2020-02-02 00:00:00',\n",
      " '2020-02-03 00:00:00', '2020-02-04 00:00:00', '2020-02-05 00:00:00',\n",
      " '2020-02-06 00:00:00', '2020-02-07 00:00:00', '2020-02-08 00:00:00',\n",
      " '2020-02-09 00:00:00', '2020-02-10 00:00:00', '2020-02-11 00:00:00',\n",
      " '2020-02-12 00:00:00', '2020-02-13 00:00:00', '2020-02-14 00:00:00',\n",
      " '2020-02-15 00:00:00', '2020-02-16 00:00:00', '2020-02-17 00:00:00',\n",
      " '2020-02-18 00:00:00', '2020-02-19 00:00:00', '2020-02-20 00:00:00',\n",
      " '2020-02-21 00:00:00', '2020-02-22 00:00:00', '2020-02-23 00:00:00',\n",
      " '2020-02-24 00:00:00']\n",
      "Length: 34, dtype: datetime64[ns]\n",
      "2020-02-25 00:00:00\n",
      "<DatetimeArray>\n",
      "['2020-01-22 00:00:00', '2020-01-23 00:00:00', '2020-01-24 00:00:00',\n",
      " '2020-01-25 00:00:00', '2020-01-26 00:00:00', '2020-01-27 00:00:00',\n",
      " '2020-01-28 00:00:00', '2020-01-29 00:00:00', '2020-01-30 00:00:00',\n",
      " '2020-01-31 00:00:00', '2020-02-01 00:00:00', '2020-02-02 00:00:00',\n",
      " '2020-02-03 00:00:00', '2020-02-04 00:00:00', '2020-02-05 00:00:00',\n",
      " '2020-02-06 00:00:00', '2020-02-07 00:00:00', '2020-02-08 00:00:00',\n",
      " '2020-02-09 00:00:00', '2020-02-10 00:00:00', '2020-02-11 00:00:00',\n",
      " '2020-02-12 00:00:00', '2020-02-13 00:00:00', '2020-02-14 00:00:00',\n",
      " '2020-02-15 00:00:00', '2020-02-16 00:00:00', '2020-02-17 00:00:00',\n",
      " '2020-02-18 00:00:00', '2020-02-19 00:00:00', '2020-02-20 00:00:00',\n",
      " '2020-02-21 00:00:00', '2020-02-22 00:00:00', '2020-02-23 00:00:00',\n",
      " '2020-02-24 00:00:00', '2020-02-25 00:00:00']\n",
      "Length: 35, dtype: datetime64[ns]\n",
      "2020-02-26 00:00:00\n",
      "<DatetimeArray>\n",
      "['2020-01-22 00:00:00', '2020-01-23 00:00:00', '2020-01-24 00:00:00',\n",
      " '2020-01-25 00:00:00', '2020-01-26 00:00:00', '2020-01-27 00:00:00',\n",
      " '2020-01-28 00:00:00', '2020-01-29 00:00:00', '2020-01-30 00:00:00',\n",
      " '2020-01-31 00:00:00', '2020-02-01 00:00:00', '2020-02-02 00:00:00',\n",
      " '2020-02-03 00:00:00', '2020-02-04 00:00:00', '2020-02-05 00:00:00',\n",
      " '2020-02-06 00:00:00', '2020-02-07 00:00:00', '2020-02-08 00:00:00',\n",
      " '2020-02-09 00:00:00', '2020-02-10 00:00:00', '2020-02-11 00:00:00',\n",
      " '2020-02-12 00:00:00', '2020-02-13 00:00:00', '2020-02-14 00:00:00',\n",
      " '2020-02-15 00:00:00', '2020-02-16 00:00:00', '2020-02-17 00:00:00',\n",
      " '2020-02-18 00:00:00', '2020-02-19 00:00:00', '2020-02-20 00:00:00',\n",
      " '2020-02-21 00:00:00', '2020-02-22 00:00:00', '2020-02-23 00:00:00',\n",
      " '2020-02-24 00:00:00', '2020-02-25 00:00:00', '2020-02-26 00:00:00']\n",
      "Length: 36, dtype: datetime64[ns]\n",
      "2020-02-27 00:00:00\n",
      "<DatetimeArray>\n",
      "['2020-01-22 00:00:00', '2020-01-23 00:00:00', '2020-01-24 00:00:00',\n",
      " '2020-01-25 00:00:00', '2020-01-26 00:00:00', '2020-01-27 00:00:00',\n",
      " '2020-01-28 00:00:00', '2020-01-29 00:00:00', '2020-01-30 00:00:00',\n",
      " '2020-01-31 00:00:00', '2020-02-01 00:00:00', '2020-02-02 00:00:00',\n",
      " '2020-02-03 00:00:00', '2020-02-04 00:00:00', '2020-02-05 00:00:00',\n",
      " '2020-02-06 00:00:00', '2020-02-07 00:00:00', '2020-02-08 00:00:00',\n",
      " '2020-02-09 00:00:00', '2020-02-10 00:00:00', '2020-02-11 00:00:00',\n",
      " '2020-02-12 00:00:00', '2020-02-13 00:00:00', '2020-02-14 00:00:00',\n",
      " '2020-02-15 00:00:00', '2020-02-16 00:00:00', '2020-02-17 00:00:00',\n",
      " '2020-02-18 00:00:00', '2020-02-19 00:00:00', '2020-02-20 00:00:00',\n",
      " '2020-02-21 00:00:00', '2020-02-22 00:00:00', '2020-02-23 00:00:00',\n",
      " '2020-02-24 00:00:00', '2020-02-25 00:00:00', '2020-02-26 00:00:00',\n",
      " '2020-02-27 00:00:00']\n",
      "Length: 37, dtype: datetime64[ns]\n",
      "2020-02-28 00:00:00\n",
      "<DatetimeArray>\n",
      "['2020-01-22 00:00:00', '2020-01-23 00:00:00', '2020-01-24 00:00:00',\n",
      " '2020-01-25 00:00:00', '2020-01-26 00:00:00', '2020-01-27 00:00:00',\n",
      " '2020-01-28 00:00:00', '2020-01-29 00:00:00', '2020-01-30 00:00:00',\n",
      " '2020-01-31 00:00:00', '2020-02-01 00:00:00', '2020-02-02 00:00:00',\n",
      " '2020-02-03 00:00:00', '2020-02-04 00:00:00', '2020-02-05 00:00:00',\n",
      " '2020-02-06 00:00:00', '2020-02-07 00:00:00', '2020-02-08 00:00:00',\n",
      " '2020-02-09 00:00:00', '2020-02-10 00:00:00', '2020-02-11 00:00:00',\n",
      " '2020-02-12 00:00:00', '2020-02-13 00:00:00', '2020-02-14 00:00:00',\n",
      " '2020-02-15 00:00:00', '2020-02-16 00:00:00', '2020-02-17 00:00:00',\n",
      " '2020-02-18 00:00:00', '2020-02-19 00:00:00', '2020-02-20 00:00:00',\n",
      " '2020-02-21 00:00:00', '2020-02-22 00:00:00', '2020-02-23 00:00:00',\n",
      " '2020-02-24 00:00:00', '2020-02-25 00:00:00', '2020-02-26 00:00:00',\n",
      " '2020-02-27 00:00:00', '2020-02-28 00:00:00']\n",
      "Length: 38, dtype: datetime64[ns]\n",
      "2020-02-29 00:00:00\n",
      "<DatetimeArray>\n",
      "['2020-01-22 00:00:00', '2020-01-23 00:00:00', '2020-01-24 00:00:00',\n",
      " '2020-01-25 00:00:00', '2020-01-26 00:00:00', '2020-01-27 00:00:00',\n",
      " '2020-01-28 00:00:00', '2020-01-29 00:00:00', '2020-01-30 00:00:00',\n",
      " '2020-01-31 00:00:00', '2020-02-01 00:00:00', '2020-02-02 00:00:00',\n",
      " '2020-02-03 00:00:00', '2020-02-04 00:00:00', '2020-02-05 00:00:00',\n",
      " '2020-02-06 00:00:00', '2020-02-07 00:00:00', '2020-02-08 00:00:00',\n",
      " '2020-02-09 00:00:00', '2020-02-10 00:00:00', '2020-02-11 00:00:00',\n",
      " '2020-02-12 00:00:00', '2020-02-13 00:00:00', '2020-02-14 00:00:00',\n",
      " '2020-02-15 00:00:00', '2020-02-16 00:00:00', '2020-02-17 00:00:00',\n",
      " '2020-02-18 00:00:00', '2020-02-19 00:00:00', '2020-02-20 00:00:00',\n",
      " '2020-02-21 00:00:00', '2020-02-22 00:00:00', '2020-02-23 00:00:00',\n",
      " '2020-02-24 00:00:00', '2020-02-25 00:00:00', '2020-02-26 00:00:00',\n",
      " '2020-02-27 00:00:00', '2020-02-28 00:00:00', '2020-02-29 00:00:00']\n",
      "Length: 39, dtype: datetime64[ns]\n",
      "2020-03-01 00:00:00\n",
      "<DatetimeArray>\n",
      "['2020-01-22 00:00:00', '2020-01-23 00:00:00', '2020-01-24 00:00:00',\n",
      " '2020-01-25 00:00:00', '2020-01-26 00:00:00', '2020-01-27 00:00:00',\n",
      " '2020-01-28 00:00:00', '2020-01-29 00:00:00', '2020-01-30 00:00:00',\n",
      " '2020-01-31 00:00:00', '2020-02-01 00:00:00', '2020-02-02 00:00:00',\n",
      " '2020-02-03 00:00:00', '2020-02-04 00:00:00', '2020-02-05 00:00:00',\n",
      " '2020-02-06 00:00:00', '2020-02-07 00:00:00', '2020-02-08 00:00:00',\n",
      " '2020-02-09 00:00:00', '2020-02-10 00:00:00', '2020-02-11 00:00:00',\n",
      " '2020-02-12 00:00:00', '2020-02-13 00:00:00', '2020-02-14 00:00:00',\n",
      " '2020-02-15 00:00:00', '2020-02-16 00:00:00', '2020-02-17 00:00:00',\n",
      " '2020-02-18 00:00:00', '2020-02-19 00:00:00', '2020-02-20 00:00:00',\n",
      " '2020-02-21 00:00:00', '2020-02-22 00:00:00', '2020-02-23 00:00:00',\n",
      " '2020-02-24 00:00:00', '2020-02-25 00:00:00', '2020-02-26 00:00:00',\n",
      " '2020-02-27 00:00:00', '2020-02-28 00:00:00', '2020-02-29 00:00:00',\n",
      " '2020-03-01 00:00:00']\n",
      "Length: 40, dtype: datetime64[ns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_1148\\3429718920.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_data['Cumulative Date'] = i\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_1148\\3429718920.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_data['Cumulative Date'] = i\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_1148\\3429718920.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_data['Cumulative Date'] = i\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_1148\\3429718920.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_data['Cumulative Date'] = i\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_1148\\3429718920.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_data['Cumulative Date'] = i\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_1148\\3429718920.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_data['Cumulative Date'] = i\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_1148\\3429718920.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_data['Cumulative Date'] = i\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_1148\\3429718920.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_data['Cumulative Date'] = i\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_1148\\3429718920.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_data['Cumulative Date'] = i\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_1148\\3429718920.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_data['Cumulative Date'] = i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-02 00:00:00\n",
      "<DatetimeArray>\n",
      "['2020-01-22 00:00:00', '2020-01-23 00:00:00', '2020-01-24 00:00:00',\n",
      " '2020-01-25 00:00:00', '2020-01-26 00:00:00', '2020-01-27 00:00:00',\n",
      " '2020-01-28 00:00:00', '2020-01-29 00:00:00', '2020-01-30 00:00:00',\n",
      " '2020-01-31 00:00:00', '2020-02-01 00:00:00', '2020-02-02 00:00:00',\n",
      " '2020-02-03 00:00:00', '2020-02-04 00:00:00', '2020-02-05 00:00:00',\n",
      " '2020-02-06 00:00:00', '2020-02-07 00:00:00', '2020-02-08 00:00:00',\n",
      " '2020-02-09 00:00:00', '2020-02-10 00:00:00', '2020-02-11 00:00:00',\n",
      " '2020-02-12 00:00:00', '2020-02-13 00:00:00', '2020-02-14 00:00:00',\n",
      " '2020-02-15 00:00:00', '2020-02-16 00:00:00', '2020-02-17 00:00:00',\n",
      " '2020-02-18 00:00:00', '2020-02-19 00:00:00', '2020-02-20 00:00:00',\n",
      " '2020-02-21 00:00:00', '2020-02-22 00:00:00', '2020-02-23 00:00:00',\n",
      " '2020-02-24 00:00:00', '2020-02-25 00:00:00', '2020-02-26 00:00:00',\n",
      " '2020-02-27 00:00:00', '2020-02-28 00:00:00', '2020-02-29 00:00:00',\n",
      " '2020-03-01 00:00:00', '2020-03-02 00:00:00']\n",
      "Length: 41, dtype: datetime64[ns]\n",
      "2020-03-03 00:00:00\n",
      "<DatetimeArray>\n",
      "['2020-01-22 00:00:00', '2020-01-23 00:00:00', '2020-01-24 00:00:00',\n",
      " '2020-01-25 00:00:00', '2020-01-26 00:00:00', '2020-01-27 00:00:00',\n",
      " '2020-01-28 00:00:00', '2020-01-29 00:00:00', '2020-01-30 00:00:00',\n",
      " '2020-01-31 00:00:00', '2020-02-01 00:00:00', '2020-02-02 00:00:00',\n",
      " '2020-02-03 00:00:00', '2020-02-04 00:00:00', '2020-02-05 00:00:00',\n",
      " '2020-02-06 00:00:00', '2020-02-07 00:00:00', '2020-02-08 00:00:00',\n",
      " '2020-02-09 00:00:00', '2020-02-10 00:00:00', '2020-02-11 00:00:00',\n",
      " '2020-02-12 00:00:00', '2020-02-13 00:00:00', '2020-02-14 00:00:00',\n",
      " '2020-02-15 00:00:00', '2020-02-16 00:00:00', '2020-02-17 00:00:00',\n",
      " '2020-02-18 00:00:00', '2020-02-19 00:00:00', '2020-02-20 00:00:00',\n",
      " '2020-02-21 00:00:00', '2020-02-22 00:00:00', '2020-02-23 00:00:00',\n",
      " '2020-02-24 00:00:00', '2020-02-25 00:00:00', '2020-02-26 00:00:00',\n",
      " '2020-02-27 00:00:00', '2020-02-28 00:00:00', '2020-02-29 00:00:00',\n",
      " '2020-03-01 00:00:00', '2020-03-02 00:00:00', '2020-03-03 00:00:00']\n",
      "Length: 42, dtype: datetime64[ns]\n",
      "2020-03-04 00:00:00\n",
      "<DatetimeArray>\n",
      "['2020-01-22 00:00:00', '2020-01-23 00:00:00', '2020-01-24 00:00:00',\n",
      " '2020-01-25 00:00:00', '2020-01-26 00:00:00', '2020-01-27 00:00:00',\n",
      " '2020-01-28 00:00:00', '2020-01-29 00:00:00', '2020-01-30 00:00:00',\n",
      " '2020-01-31 00:00:00', '2020-02-01 00:00:00', '2020-02-02 00:00:00',\n",
      " '2020-02-03 00:00:00', '2020-02-04 00:00:00', '2020-02-05 00:00:00',\n",
      " '2020-02-06 00:00:00', '2020-02-07 00:00:00', '2020-02-08 00:00:00',\n",
      " '2020-02-09 00:00:00', '2020-02-10 00:00:00', '2020-02-11 00:00:00',\n",
      " '2020-02-12 00:00:00', '2020-02-13 00:00:00', '2020-02-14 00:00:00',\n",
      " '2020-02-15 00:00:00', '2020-02-16 00:00:00', '2020-02-17 00:00:00',\n",
      " '2020-02-18 00:00:00', '2020-02-19 00:00:00', '2020-02-20 00:00:00',\n",
      " '2020-02-21 00:00:00', '2020-02-22 00:00:00', '2020-02-23 00:00:00',\n",
      " '2020-02-24 00:00:00', '2020-02-25 00:00:00', '2020-02-26 00:00:00',\n",
      " '2020-02-27 00:00:00', '2020-02-28 00:00:00', '2020-02-29 00:00:00',\n",
      " '2020-03-01 00:00:00', '2020-03-02 00:00:00', '2020-03-03 00:00:00',\n",
      " '2020-03-04 00:00:00']\n",
      "Length: 43, dtype: datetime64[ns]\n",
      "2020-03-05 00:00:00\n",
      "<DatetimeArray>\n",
      "['2020-01-22 00:00:00', '2020-01-23 00:00:00', '2020-01-24 00:00:00',\n",
      " '2020-01-25 00:00:00', '2020-01-26 00:00:00', '2020-01-27 00:00:00',\n",
      " '2020-01-28 00:00:00', '2020-01-29 00:00:00', '2020-01-30 00:00:00',\n",
      " '2020-01-31 00:00:00', '2020-02-01 00:00:00', '2020-02-02 00:00:00',\n",
      " '2020-02-03 00:00:00', '2020-02-04 00:00:00', '2020-02-05 00:00:00',\n",
      " '2020-02-06 00:00:00', '2020-02-07 00:00:00', '2020-02-08 00:00:00',\n",
      " '2020-02-09 00:00:00', '2020-02-10 00:00:00', '2020-02-11 00:00:00',\n",
      " '2020-02-12 00:00:00', '2020-02-13 00:00:00', '2020-02-14 00:00:00',\n",
      " '2020-02-15 00:00:00', '2020-02-16 00:00:00', '2020-02-17 00:00:00',\n",
      " '2020-02-18 00:00:00', '2020-02-19 00:00:00', '2020-02-20 00:00:00',\n",
      " '2020-02-21 00:00:00', '2020-02-22 00:00:00', '2020-02-23 00:00:00',\n",
      " '2020-02-24 00:00:00', '2020-02-25 00:00:00', '2020-02-26 00:00:00',\n",
      " '2020-02-27 00:00:00', '2020-02-28 00:00:00', '2020-02-29 00:00:00',\n",
      " '2020-03-01 00:00:00', '2020-03-02 00:00:00', '2020-03-03 00:00:00',\n",
      " '2020-03-04 00:00:00', '2020-03-05 00:00:00']\n",
      "Length: 44, dtype: datetime64[ns]\n",
      "2020-03-06 00:00:00\n",
      "<DatetimeArray>\n",
      "['2020-01-22 00:00:00', '2020-01-23 00:00:00', '2020-01-24 00:00:00',\n",
      " '2020-01-25 00:00:00', '2020-01-26 00:00:00', '2020-01-27 00:00:00',\n",
      " '2020-01-28 00:00:00', '2020-01-29 00:00:00', '2020-01-30 00:00:00',\n",
      " '2020-01-31 00:00:00', '2020-02-01 00:00:00', '2020-02-02 00:00:00',\n",
      " '2020-02-03 00:00:00', '2020-02-04 00:00:00', '2020-02-05 00:00:00',\n",
      " '2020-02-06 00:00:00', '2020-02-07 00:00:00', '2020-02-08 00:00:00',\n",
      " '2020-02-09 00:00:00', '2020-02-10 00:00:00', '2020-02-11 00:00:00',\n",
      " '2020-02-12 00:00:00', '2020-02-13 00:00:00', '2020-02-14 00:00:00',\n",
      " '2020-02-15 00:00:00', '2020-02-16 00:00:00', '2020-02-17 00:00:00',\n",
      " '2020-02-18 00:00:00', '2020-02-19 00:00:00', '2020-02-20 00:00:00',\n",
      " '2020-02-21 00:00:00', '2020-02-22 00:00:00', '2020-02-23 00:00:00',\n",
      " '2020-02-24 00:00:00', '2020-02-25 00:00:00', '2020-02-26 00:00:00',\n",
      " '2020-02-27 00:00:00', '2020-02-28 00:00:00', '2020-02-29 00:00:00',\n",
      " '2020-03-01 00:00:00', '2020-03-02 00:00:00', '2020-03-03 00:00:00',\n",
      " '2020-03-04 00:00:00', '2020-03-05 00:00:00', '2020-03-06 00:00:00']\n",
      "Length: 45, dtype: datetime64[ns]\n",
      "2020-03-07 00:00:00\n",
      "<DatetimeArray>\n",
      "['2020-01-22 00:00:00', '2020-01-23 00:00:00', '2020-01-24 00:00:00',\n",
      " '2020-01-25 00:00:00', '2020-01-26 00:00:00', '2020-01-27 00:00:00',\n",
      " '2020-01-28 00:00:00', '2020-01-29 00:00:00', '2020-01-30 00:00:00',\n",
      " '2020-01-31 00:00:00', '2020-02-01 00:00:00', '2020-02-02 00:00:00',\n",
      " '2020-02-03 00:00:00', '2020-02-04 00:00:00', '2020-02-05 00:00:00',\n",
      " '2020-02-06 00:00:00', '2020-02-07 00:00:00', '2020-02-08 00:00:00',\n",
      " '2020-02-09 00:00:00', '2020-02-10 00:00:00', '2020-02-11 00:00:00',\n",
      " '2020-02-12 00:00:00', '2020-02-13 00:00:00', '2020-02-14 00:00:00',\n",
      " '2020-02-15 00:00:00', '2020-02-16 00:00:00', '2020-02-17 00:00:00',\n",
      " '2020-02-18 00:00:00', '2020-02-19 00:00:00', '2020-02-20 00:00:00',\n",
      " '2020-02-21 00:00:00', '2020-02-22 00:00:00', '2020-02-23 00:00:00',\n",
      " '2020-02-24 00:00:00', '2020-02-25 00:00:00', '2020-02-26 00:00:00',\n",
      " '2020-02-27 00:00:00', '2020-02-28 00:00:00', '2020-02-29 00:00:00',\n",
      " '2020-03-01 00:00:00', '2020-03-02 00:00:00', '2020-03-03 00:00:00',\n",
      " '2020-03-04 00:00:00', '2020-03-05 00:00:00', '2020-03-06 00:00:00',\n",
      " '2020-03-07 00:00:00']\n",
      "Length: 46, dtype: datetime64[ns]\n",
      "(243000, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_1148\\3429718920.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_data['Cumulative Date'] = i\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_1148\\3429718920.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_data['Cumulative Date'] = i\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_1148\\3429718920.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_data['Cumulative Date'] = i\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_1148\\3429718920.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_data['Cumulative Date'] = i\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_1148\\3429718920.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_data['Cumulative Date'] = i\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_1148\\3429718920.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_data['Cumulative Date'] = i\n"
     ]
    }
   ],
   "source": [
    "# puting unique values in list\n",
    "dates = full_join3['Date'].unique()\n",
    "\n",
    "#creating a df with unique\n",
    "dates = pd.DataFrame(dates, columns=['Date'])\n",
    "\n",
    "# Ordering df\n",
    "dates = dates.sort_values(by=['Date'])\n",
    "\n",
    "# Creating an ordered list now\n",
    "dates = full_join3['Date'].unique()\n",
    "\n",
    "print(full_join3.shape)\n",
    "\n",
    "try:\n",
    "    del concat_data\n",
    "except:\n",
    "    print()\n",
    "    \n",
    "try:\n",
    "    del final_concat_data\n",
    "except:\n",
    "    print()\n",
    "    \n",
    "\n",
    "for i in dates:\n",
    "    new_data = full_join3[full_join3['Date'] == i]\n",
    "    new_data['Cumulative Date'] = i\n",
    "    print(i)\n",
    "    \n",
    "    try:     \n",
    "        concat_data = pd.concat([concat_data, new_data], ignore_index = True)\n",
    "        concat_data['Cumulative Date 2'] = i\n",
    "        print(concat_data['Date'].unique())\n",
    "        \n",
    "        try:\n",
    "            final_concat_data = pd.concat([final_concat_data, concat_data], ignore_index = True)\n",
    "        except:\n",
    "            final_concat_data = concat_data\n",
    "\n",
    "    except:\n",
    "        concat_data = new_data\n",
    "        \n",
    "print(final_concat_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "abea6261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting the data\n",
    "\n",
    "final_concat_data.to_csv('CoronaVirus PowerBI Raw - Cumulative Test', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0a7f7f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>Date</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Recovered</th>\n",
       "      <th>Month-Year</th>\n",
       "      <th>Confirmed Daily</th>\n",
       "      <th>Deaths Daily</th>\n",
       "      <th>Recovered Daily</th>\n",
       "      <th>Hubei Vs Rest of the World</th>\n",
       "      <th>Cumulative Date</th>\n",
       "      <th>Cumulative Date 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anhui</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>31.8257</td>\n",
       "      <td>117.2264</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Jan-2020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Rest of the World</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>2020-01-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beijing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>40.1824</td>\n",
       "      <td>116.4142</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Jan-2020</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Rest of the World</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>2020-01-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chongqing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>30.0572</td>\n",
       "      <td>107.8740</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Jan-2020</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Rest of the World</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>2020-01-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fujian</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>26.0789</td>\n",
       "      <td>117.9874</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Jan-2020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Rest of the World</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>2020-01-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gansu</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>36.0611</td>\n",
       "      <td>103.8343</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Jan-2020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Rest of the World</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>2020-01-23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province/State  Country/Region      Lat      Long       Date  Confirmed  \\\n",
       "0          Anhui  Mainland China  31.8257  117.2264 2020-01-22          1   \n",
       "1        Beijing  Mainland China  40.1824  116.4142 2020-01-22         14   \n",
       "2      Chongqing  Mainland China  30.0572  107.8740 2020-01-22          6   \n",
       "3         Fujian  Mainland China  26.0789  117.9874 2020-01-22          1   \n",
       "4          Gansu  Mainland China  36.0611  103.8343 2020-01-22          0   \n",
       "\n",
       "   Deaths  Recovered Month-Year  Confirmed Daily  Deaths Daily  \\\n",
       "0       0          0   Jan-2020              1.0           0.0   \n",
       "1       0          0   Jan-2020             14.0           0.0   \n",
       "2       0          0   Jan-2020              6.0           0.0   \n",
       "3       0          0   Jan-2020              1.0           0.0   \n",
       "4       0          0   Jan-2020              0.0           0.0   \n",
       "\n",
       "   Recovered Daily Hubei Vs Rest of the World Cumulative Date  \\\n",
       "0              0.0          Rest of the World      2020-01-22   \n",
       "1              0.0          Rest of the World      2020-01-22   \n",
       "2              0.0          Rest of the World      2020-01-22   \n",
       "3              0.0          Rest of the World      2020-01-22   \n",
       "4              0.0          Rest of the World      2020-01-22   \n",
       "\n",
       "  Cumulative Date 2  \n",
       "0        2020-01-23  \n",
       "1        2020-01-23  \n",
       "2        2020-01-23  \n",
       "3        2020-01-23  \n",
       "4        2020-01-23  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_concat_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0414afc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
